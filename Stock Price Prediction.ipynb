{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb5bdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "#import pandas_datareader.data as web\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential  # linear stack of layers\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM        # Long Short-Term Memory layer\n",
    "from keras.layers import Dropout     # simple way to prevent overfitting\n",
    "\n",
    "\n",
    "\n",
    "# Configuration\n",
    "\n",
    "SHARE = 'AAPL'\n",
    "SERVICE = 'fred' #'quandl' #'yahoo'\n",
    "\n",
    "PREDICTORS = ['Open']  #['High', 'Low', 'Open']   # column names with prices\n",
    "TARGET = 'Open'\n",
    "\n",
    "TIMESTEP = 90  # the number of previous days used for prediction\n",
    "\n",
    "START_DATE = datetime.datetime(2010, 1, 1)  # doesn't work for Kaggle Notebook, train set is used instead \n",
    "END_DATE = datetime.datetime(2019, 9, 30)\n",
    "\n",
    "START_DATE_TO_PREDICT = datetime.datetime(2019, 10, 1)  # doesn't work for Kaggle,test set is used instead\n",
    "END_DATE_TO_PREDICT = datetime.datetime(2019, 10, 31)\n",
    "\n",
    "N_EPOCHS = 100\n",
    "\n",
    "\n",
    "# Download stock price data\n",
    "\n",
    "# For some reason web.DataReader doesn't work on Kaggle\n",
    "\n",
    "#df_train = web.DataReader(SHARE, SERVICE, START_DATE, END_DATE)\n",
    "#df_test = web.DataReader(SHARE, SERVICE, START_DATE_TO_PREDICT, END_DATE_TO_PREDICT)\n",
    "\n",
    "df_train = pd.read_csv('Google_Stock_Price_Train.csv')\n",
    "df_test = pd.read_csv('Google_Stock_Price_Test.csv')\n",
    "\n",
    "\n",
    "df_test.tail()\n",
    "\n",
    "\n",
    "# Data preprocessing\n",
    "\n",
    "# Fix for used input files on Kaggle\n",
    "df_train['Date'] = pd.to_datetime(df_train['Date'])\n",
    "df_test['Date'] = pd.to_datetime(df_test['Date'])\n",
    "\n",
    "df_train.set_index('Date', inplace=True)\n",
    "df_test.set_index('Date', inplace=True)\n",
    "\n",
    "# Removing irrelevant columns\n",
    "df_train = df_train[PREDICTORS]\n",
    "df_test = df_test[PREDICTORS]\n",
    "\n",
    "\n",
    "\n",
    "# Creating numpy 2-dim array for the training set\n",
    "# size N x K, where N - number of observations\n",
    "# K - number of predictors\n",
    "\n",
    "training_set = df_train.values\n",
    "\n",
    "# Feature Scaling\n",
    "sc = MinMaxScaler(feature_range = (0, 1))\n",
    "training_set_scaled = sc.fit_transform(training_set)\n",
    "\n",
    "\n",
    "# Creating a data structure with timesteps and 1 output\n",
    "# X_train - 3-dim array size of N x M x K, where \n",
    "# N - number of observations\n",
    "# M - number of previous days (TIMESTEP)\n",
    "# K - number of predictors/indicators\n",
    " \n",
    "X_train = []\n",
    "y_train = []\n",
    "target_col_index = df_train.columns.get_loc(TARGET)\n",
    "for i in range(TIMESTEP, len(training_set)):\n",
    "    X_train.append(training_set_scaled[i-TIMESTEP:i, :])       # X_train - list of Numpy arrays\n",
    "    y_train.append(training_set_scaled[i, target_col_index])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)        # convert list to Numpy array\n",
    "\n",
    "\n",
    "\n",
    "# Building the RNN\n",
    "\n",
    "\n",
    "# Initialising the RNN\n",
    "regressor = Sequential()\n",
    "\n",
    "# Adding the first LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a second LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a third LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# Adding a fourth LSTM layer and some Dropout regularisation\n",
    "regressor.add(LSTM(units = 50))\n",
    "regressor.add(Dropout(0.2))\n",
    "# Adding the output layer - dense layer \n",
    "# classic fully connected neural network layer : each input node is connected to each output node\n",
    "regressor.add(Dense(units = 1))\n",
    "\n",
    "# Compiling the RNN\n",
    "# use MSE instead RMSE (Root Mean Squared Error) because we are more interested in the directions taken by our predictions, rather than the closeness of their values to the real stock price\n",
    "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "# Fitting the RNN to the Training set\n",
    "regressor.fit(X_train, y_train, epochs = N_EPOCHS, batch_size = 32)\n",
    "\n",
    "\n",
    "# Extracting real prices\n",
    "real_stock_price = df_test[TARGET].values\n",
    "\n",
    "# Preparing input data for making predictions\n",
    "df_total = df_train.append(df_test)\n",
    "inputs = df_total[len(df_total) - len(df_test) - TIMESTEP:][PREDICTORS]\n",
    "\n",
    "inputs = sc.transform(inputs)\n",
    "\n",
    "\n",
    "X_test = []\n",
    "for i in range(TIMESTEP, TIMESTEP+len(df_test)):\n",
    "    X_test.append(inputs[i-TIMESTEP:i, :])\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# Making the predictions\n",
    "\n",
    "predicted_stock_price = regressor.predict(X_test)\n",
    "\n",
    "# to perform inverse scaler transformation, at first we need to transform \n",
    "# 1-dimensional array with predicted prices to 2-dim array of size N x K, \n",
    "# where N = number of observations/predictions. \n",
    "# K = number of predictors\n",
    "\n",
    "temp_matrix = np.zeros((len(predicted_stock_price), len(PREDICTORS)))\n",
    "temp_matrix[:,target_col_index:target_col_index+1] = predicted_stock_price  # temp_matrix[:,[target_col_index]] = predicted_stock_price    \n",
    "\n",
    "predicted_stock_price = sc.inverse_transform(temp_matrix)[:,target_col_index]\n",
    "\n",
    "\n",
    "#df_predicted = pd.DataFrame(index=df_test.index)\n",
    "#df_predicted[TARGET] = predicted_stock_price\n",
    "\n",
    "df_test['Predicted price'] = predicted_stock_price\n",
    "df_test[TARGET].plot(figsize=(16,4),legend=True)\n",
    "df_test['Predicted price'].plot(figsize=(16,4),legend=True)\n",
    "plt.legend(['Real price', 'Predicted price'])\n",
    "plt.title('RNN - ' + SHARE + ' Stock Price Prediction')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Evaluating model\n",
    "rmse = math.sqrt(mean_squared_error(real_stock_price, predicted_stock_price))\n",
    "print(\"The RMSE is {:.3f}.\".format(rmse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
